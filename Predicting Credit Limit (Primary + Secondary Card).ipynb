{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data Set.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f940e93877e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data Set.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data Set.xlsx'"
     ]
    }
   ],
   "source": [
    "Data = pd.read_excel(\"Data Set.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Dispaly Options so that all the columns can be viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.width',1000)\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Creating target \"Total_Spend\" variable by combining cardspent + card2spent and later dropping them\n",
    "#### 2. Removing duplicate categorical and log variable of the numerical variable from the data set\n",
    "#### 3. Replacing the value \"-1\" by 0 in spoused and carvalue varibles and null values by 0.0 in continous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Total_Spend'] = Data['cardspent'] + Data['card2spent']\n",
    "Data = Data.drop(columns={'cardspent',\"card2spent\"},axis = 1)\n",
    "Data = Data.drop(columns={\"agecat\",\"edcat\",\"empcat\",\"lninc\",\"inccat\",\"lncreddebt\",\"lnothdebt\",\"spousedcat\",\"addresscat\",\"commutecat\",\"cardtenurecat\",\"lnlongmon\",\"lnlongten\",\"lntollmon\",\"lntollten\",\"lnequipmon\",\"lnequipten\",\"lncardmon\",\"lncardten\",\"lnwiremon\",\"lnwireten\"},axis = 1)\n",
    "Data = Data.drop(columns={'custid'},axis=1)\n",
    "Data = Data.drop(columns={'birthmonth'},axis=1)\n",
    "Data = Data.drop(columns={'carcatvalue'},axis=1)\n",
    "Data = Data.drop(columns={'card2tenurecat'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.spoused[Data.spoused==-1]=0\n",
    "Data.carvalue[Data.carvalue==-1] = 0\n",
    "Data.cardten[Data.cardten.isna()==True] = 0.0\n",
    "Data.longten[Data.longten.isna()==True] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.townsize = Data.fillna(Data.townsize.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(x):\n",
    "    x = x.fillna(x.mean())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data.apply(lambda x: missing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(x):\n",
    "    lc = x.quantile(0.01)\n",
    "    uc = x.quantile(0.99)\n",
    "    return x.clip(lower = lc, upper = uc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data= Data.apply(lambda x : outliers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Data.Total_Spend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating log of the target  varaible as target variable does not follow normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Total_Spend = np.log(Data.Total_Spend)\n",
    "sns.distplot(Data.Total_Spend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seprating Numerical data from the data set with the help of data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_num = Data.loc[:,['age','ed',\"employ\",'income','debtinc','creddebt','othdebt','spoused','reside','pets','pets_cats','pets_dogs','pets_birds','pets_reptiles','pets_small',\n",
    "                      'pets_saltfish','pets_freshfish','address','cars','carvalue','commutetime','cardtenure','card2tenure','tenure','longmon',\n",
    "                      'longten','tollmon','tollten','equipmon','equipten','cardmon','cardten','wiremon','wireten','hourstv','Total_Spend']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_num.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Analysis of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in Data_num.columns:\n",
    "#    Data_num[i].hist()\n",
    "#    plt.xlabel(str(i))\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. More than 30% have job experience less than 5 years\n",
    "2. 50% of the customers have income less than equal to 50K\n",
    "3. 60% customers have credit debt less than 2K\n",
    "4. Customers genrally have 2 cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_summary(x):\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.sum(), x.mean(), x.median(),  x.std(), x.var(), x.std()/x.mean(), x.min(), x.dropna().quantile(0.01), x.dropna().quantile(0.05),x.dropna().quantile(0.10),x.dropna().quantile(0.25),x.dropna().quantile(0.50),x.dropna().quantile(0.75), x.dropna().quantile(0.90),x.dropna().quantile(0.95), x.dropna().quantile(0.99),x.max()], \n",
    "                  index=['N', 'NMISS', 'SUM', 'MEAN','MEDIAN', 'STD', 'VAR', 'CV','MIN', 'P1' , 'P5' ,'P10' ,'P25' ,'P50' ,'P75' ,'P90' ,'P95' ,'P99' ,'MAX'])\n",
    "Data_num.apply(lambda x: var_summary(x)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis of Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in Data_num.columns:\n",
    "#    sns.scatterplot(data=Data_num,x=Data_num[i],y=\"Total_Spend\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As income increases their is a increase in the total_spend, creddebt & otherdebt also have same realtion with income\n",
    "2. Carvalue have a positive corealtion with total_spend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seprating Categorical Features from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cat = Data.loc[:,(Data.columns.difference(['age','ed',\"employ\",'income','debtinc','creddebt','othdebt','spoused','reside','pets','pets_cats','pets_dogs','pets_birds','pets_reptiles','pets_small',\n",
    "                      'pets_saltfish','pets_freshfish','address','cars','carvalue','commutetime','cardtenure','card2tenure','tenure','longmon',\n",
    "                      'longten','tollmon','tollten','equipmon','equipten','cardmon','cardten','wiremon','wireten','hourstv','Total_Spend']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Analysis of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in Data_cat.columns:\n",
    "#    Data_cat[i].hist()\n",
    "#    plt.xlabel(str(i))\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis of Categorical Variable\n",
    "\n",
    "1. More than 70% of customers uses CallCard Service\n",
    "2. 60% of the customers have not leased/bought the car in previous years and they are not planning to buy in coming year as well\n",
    "3. Approx 50% of customers have Discover and Visa as their primary card\n",
    "4. Nearly 50% customers have Visa and Mastercard as their secondary card\n",
    "5. Customer tend to prefer have \"other & Airline Miles\" as benefits in their secondary card\n",
    "6. 80% customer prefer to have no fees on the card be it secondary or primary card\n",
    "7. Nearly 20% of customers have changed their provider in last month\n",
    "8. More than 70% of customers have not defaulted in any loan \n",
    "9. Most of the customer have \"Single type\" family\n",
    "10. 30% of the customer belong to \"Sales & office\" job category\n",
    "11. 50% of the customer are not married\n",
    "12. Nearly 80% of the customer have not stated their reason for being a customer\n",
    "13. 90% of the customers have not responded to any of the product offered to them\n",
    "14. 90% of the customer dont belong to any union and are not retired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis of Categorical features with the target varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivaritae_cat_analysis = Data.loc[:,(Data.columns.difference(['age','ed',\"employ\",'income','debtinc','creddebt','othdebt','spoused','reside','pets','pets_cats','pets_dogs','pets_birds','pets_reptiles','pets_small',\n",
    "                      'pets_saltfish','pets_freshfish','address','cars','carvalue','commutetime','cardtenure','card2tenure','tenure','longmon',\n",
    "                      'longten','tollmon','tollten','equipmon','equipten','cardmon','cardten','wiremon','wireten','hourstv']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in bivaritae_cat_analysis.columns:\n",
    "#    sns.boxplot(x=bivaritae_cat_analysis[i],y=\"Total_Spend\",data=bivaritae_cat_analysis)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis of Categorical Variables\n",
    "1. Out of Card (1,2,3,4,5), Card 1 customers have more credit limit then other card type\n",
    "2. Out of Card2 (1,2,3,4,5), Card 1 & 4 have more credit limit then other card type\n",
    "3. People who lease Car have low credit limit as compare to those who own the car\n",
    "4. Male have higher credit limit then female\n",
    "5. People who own home have higher total_spend then people who live in rented house\n",
    "6. People who are in Service of Job Category have more credit limit then other job categories\n",
    "7. Customers who are \"Somewhat Satisfied\" With their job have higher total spend\n",
    "8. Customers who owns' OwnCd, OwnDvd, OwnPda, OwnTv, OwnVcr have higher total_spend\n",
    "9. People who are customers of bank becuase of \"Convenience\" have much higher total_spend as comapre to other customers\n",
    "10. Customers who are not retired are given more total_spend limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seprating Ordinal and nominal categorical features for one hot encoding/dummy creation of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cat_nom = Data_cat.loc[:,(Data_cat.columns.difference([\"townsize\",\"jobsat\",\"hometype\",\"polview\",\"cardtype\",\"card2type\",\"internet\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cat_nom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies( df, colname ):\n",
    "    col_dummies = pd.get_dummies(df[colname], prefix=colname, drop_first=True)\n",
    "    df = pd.concat([df, col_dummies], axis=1)\n",
    "    df.drop( colname, axis = 1, inplace = True )\n",
    "    return df\n",
    "\n",
    "for c_feature in Data_cat_nom.columns:\n",
    "    Data_cat[c_feature] = Data_cat[c_feature].astype('category')\n",
    "    Data_cat = create_dummies(Data_cat , c_feature )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data = pd.concat([Data_num,Data_cat],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre_Final_Data = Final_data.loc[:,Final_data.columns.difference(['Total_Spend'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre_Final_Data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data for prediction purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Data = ((Pre_Final_Data-Pre_Final_Data.min())/(Pre_Final_Data.max()-Pre_Final_Data.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Data['Total_Spend'] = Final_data.Total_Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = Normal_Data.loc[:,(Normal_Data.columns.difference(['Total_Spend']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Normal_Data.Total_Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(lm,n_features_to_select=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = rfe.fit(feature,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_features = feature.columns[rfe.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = feature[RFE_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variables Selected from RFE:\",feature1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select K best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = Normal_Data.loc[:,Normal_Data.columns.difference(['Total_Spend'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = Normal_Data.Total_Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skb1 = SelectKBest(f_regression,k= 30).fit(X1,Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.columns[skb1.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seprating Normalized Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Num_Data = Normal_Data.loc[:,[\"age\",\"ed\",\"employ\",\"income\",\"debtinc\",\"creddebt\",\"othdebt\",\"spoused\",\"reside\",\"pets\",\"pets_cats\",\"pets_dogs\",\"pets_birds\",\"pets_reptiles\",\"pets_small\",\"pets_saltfish\",\"pets_freshfish\",\n",
    "                                  \"address\",\"cars\",\"carvalue\",\"commutetime\",\"cardtenure\",\"card2tenure\",\"tenure\",\"longmon\",\n",
    "                                    \"longten\",\"tollmon\",\"tollten\",\"equipmon\",\"equipten\",\"cardmon\",\"cardten\",\"wiremon\",\"wireten\",\"hourstv\",\"Total_Spend\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Cat_Data = Normal_Data.loc[:,(Normal_Data.columns.difference([\"age\",\"ed\",\"employ\",\"income\",\"debtinc\",\"creddebt\",\"othdebt\",\"spoused\",\"reside\",\"pets\",\"pets_cats\",\"pets_dogs\",\"pets_birds\",\"pets_reptiles\",\"pets_small\",\"pets_saltfish\",\"pets_freshfish\",\n",
    "                                  \"address\",\"cars\",\"carvalue\",\"commutetime\",\"cardtenure\",\"card2tenure\",\"tenure\",\"longmon\",\n",
    "                                    \"longten\",\"tollmon\",\"tollten\",\"equipmon\",\"equipten\",\"cardmon\",\"cardten\",\"wiremon\",\"wireten\",\"hourstv\",\"Total_Spend\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Cat_Data['Total_Spend'] = Normal_Data.Total_Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Cat_Data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correaltion Matrix between independent and dependent variables to see the influence of numerical x variable over y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correlation = Normal_Num_Data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation.to_excel(\"Correlation1.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected Variables : ed, income, creddebt,othdebt,carvalue,wireten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Variable-Regression for Categorical and Target(Continous) Variable, selected the variables which have p_value less than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pvalue = []\n",
    "fvalue = []\n",
    "for col in Normal_Cat_Data.columns[0:len(Normal_Cat_Data.columns)-1]:\n",
    "    model = \"\"\n",
    "    formula = 'Total_Spend ~ '+col\n",
    "    model = smf.ols(formula, data = Normal_Cat_Data).fit()\n",
    "    f_pvalue.append(model.f_pvalue)\n",
    "    fvalue.append(model.fvalue)\n",
    "f_pvalue = pd.Series(f_pvalue, name = \"p_value\")\n",
    "fvalue = pd.Series(fvalue, name = \"F_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = Normal_Cat_Data.columns[0:len(Normal_Cat_Data.columns)-1]\n",
    "Annova = pd.concat([pd.Series(cols, name = \"Col_Names\"),f_pvalue,fvalue],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Annova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat_Selected_Var = Annova.Col_Names[Annova.p_value < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat_Selected = Normal_Cat_Data[Cat_Selected_Var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cat_Selected.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Data Set With the reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_Data = Normal_Num_Data.loc[:,[\"ed\",\"income\",\"creddebt\",\"othdebt\",\"carvalue\",\"wireten\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Final_Data = pd.concat([Num_Data,Cat_Selected],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Final_Data['Total_Spend'] = Normal_Data.Total_Spend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE Over Selected Variable from the result of Correlation and F-Regression Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_new = New_Final_Data.loc[:,(New_Final_Data.columns.difference(['Total_Spend']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_new = New_Final_Data.Total_Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_new = RFE(lm,n_features_to_select=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_new = rfe_new.fit(feature_new,target_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_Feature_new= feature_new.columns[rfe_new.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new_final = feature_new[RFE_Feature_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RFE Over Selected Varibles:\",features_new_final.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K Best Over Selected Variable from the result of Correlation and F-Regression Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_new\n",
    "Y = target_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skb = SelectKBest(f_regression,k = 30).fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[skb.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_DATA = Final_data.loc[:,Final_data.columns.difference(['Total_Spend'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stat_model = sc.fit(PCA_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform_data = Stat_model.transform(PCA_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform_data = pd.DataFrame(Transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform_data.columns = PCA_DATA.columns\n",
    "Transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = pca.fit(Transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(pca_model.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data = pd.DataFrame(pca.transform(Transform_data),columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12','PC13','PC14','PC15','PC16',\n",
    "                                                                'PC17','PC18','PC19','PC20','PC21','PC22','PC23','PC24','PC25','PC26','PC27','PC28','PC29','PC30'\n",
    "                                                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loadings =  pd.DataFrame((pca_model.components_.T * np.sqrt(pca_model.explained_variance_)).T,columns=Transform_data.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loadings.to_excel(\"PCA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_Variables = [\"card2tenure\",\"cardtenure\",\"tenure\",\"wireless_1\",\"wiremon\",\"equipmon\",\"tollfree_1\",\"carvalue\",\n",
    "                \"marital_1\",\"commutecar_1\",\"townsize\",\"pets\",\"carbought_1\",\"card_2\",\"cartype_1\",\"card_4\",\n",
    "                \"reason_9\",\"commute_4\",\"commute_8\",\"commute_3\",\"commute_10\",\"card2benefit_3\",\"commute_2\",\n",
    "                \"card2benefit_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA VARIABLES :\",PCA_Variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature1.columns) #RFE_ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_new_final.columns) #RFE_REDUCED_FROM_FREGRESSION & CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns[skb.get_support()]) #KBest on Reduced variables from F-Regresssion and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.columns[skb1.get_support()] #K best on the entire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Selected variabels from the conclsion of multiple varible reduction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Variables= Normal_Data.loc[:,[\"card2_2\",\"card2_3\",\"card2_4\",\"card2_5\",\"card_2\",\"card_3\",\"card_4\",\"card_5\",\"carown_0\",\"carown_1\",\"carvalue\",\"creddebt\",\"othdebt\",\"ed\",\"income\",\"gender_1\",\"wireten\",\"internet\",\"owncd_1\",\"owndvd_1\",\"owntv_1\",\"ownvcr_1\",\"reason_2\",\"reason_4\",\"retire_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Selected_Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing VIF to check the Multicolinearity among the selected vairbales and further removing the vairbels one by one which have VIF score more than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "#the independent variables set \n",
    "X = Selected_Variables \n",
    "  \n",
    "# VIF dataframe \n",
    "vif_data = pd.DataFrame() \n",
    "vif_data[\"feature\"] = X.columns \n",
    "  \n",
    "# calculating VIF for each feature \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
    "                          for i in range(len(X.columns))] \n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables with high VIF are carown_1,carvalue,ed,owncd_1,owndvd_1,owntv_1,ownvcr_1. We will remove them one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Variables= Selected_Variables.loc[:,Selected_Variables.columns.difference([\"carown_1\",\"carvalue\",\"ed\",\"owncd_1\",\"owndvd_1\",\"owntv_1\",\"ownvcr_1\",\"ownvcr_1\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Variables['Total_Spend'] = Normal_Data.Total_Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"+\".join(Selected_Variables.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into test and train for Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(Selected_Variables,test_size = 0.3,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula=\"Total_Spend~card2_2+card2_3+card2_4+card2_5+card_2+card_3+card_4+card_5+carown_0+gender_1+income+reason_2+retire_1\",data=train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Y = 6.6855-0.4036*card2_2-0.3763*card2_3-0.4255*card2_4-0.2967*card2_5-0.5860*card_2-0.6073*card_3-0.7080*card_4-0.5245*card_5-0.0669*carown_0-0.0464*gender_1+1.1351*income+0.2671*reason_2-0.2065*retire_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on Training and metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pred'] = np.exp(model.predict(train))\n",
    "train['Total_Spend'] = np.exp(train.Total_Spend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train = train.Total_Spend - train.pred\n",
    "abs_error_train = abs(error_train)\n",
    "pct_abs_error_train = abs_error_train/train.Total_Spend\n",
    "MAPE_train = pct_abs_error_train.mean()\n",
    "print(\"MAPE TRAIN:\",MAPE_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on Test and Metric Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = np.exp(model.predict(test))\n",
    "test['Total_Spend'] = np.exp(test.Total_Spend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_test = test.Total_Spend - test.pred\n",
    "abs_error_test = abs(error_test)\n",
    "pct_abs_error_test = abs_error_test/test.Total_Spend\n",
    "Mape_test = pct_abs_error_test.mean()\n",
    "print(\"MAPE TEST:\",Mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_Train_ols= metrics.mean_squared_error(train.pred,train.Total_Spend)**(1/2)\n",
    "RMSE_Test_ols= metrics.mean_squared_error(test.pred,test.Total_Spend)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = {\"R_Square_ols\":[model.rsquared],\"Mape_Train_ols\":MAPE_train,\"Mape_Test_ols\":Mape_test,\"RMSE_Train_ols\":RMSE_Train_ols,\"RMSE_Test_ols\":RMSE_Test_ols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = pd.DataFrame.from_dict(ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the residual graph, it should follow normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(model.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the correlation between actual and error, actual and predcited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation Between Actucal and Error on Train:\",stats.stats.pearsonr(y=train.Total_Spend,x=error_train))\n",
    "print(\"Correlation Between Actucal and Predicted on Train:\",stats.stats.pearsonr(y=train.Total_Spend,x=train.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation Between Actucal and Error on Test:\",stats.stats.pearsonr(y=test.Total_Spend,x=error_test))\n",
    "print(\"Correlation Between Actucal and Predicted on Test:\",stats.stats.pearsonr(y=test.Total_Spend,x=test.pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Deciles']=pd.qcut(train['pred'],10, labels=False)\n",
    "Predicted_avg = train[['Deciles','pred']].groupby(train.Deciles).mean().sort_index(ascending=False)['pred']\n",
    "Actual_avg = train[['Deciles','Total_Spend']].groupby(train.Deciles).mean().sort_index(ascending=False)['Total_Spend']\n",
    "\n",
    "Decile_analysis_train = pd.concat([Predicted_avg, Actual_avg], axis=1)\n",
    "\n",
    "Decile_analysis_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decile_analysis_train.to_excel(\"Decile_Train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test['Deciles']=pd.qcut(test['pred'],10, labels=False)\n",
    "Predicted_avg = test[['Deciles','pred']].groupby(test.Deciles).mean().sort_index(ascending=False)['pred']\n",
    "Actual_avg = test[['Deciles','Total_Spend']].groupby(test.Deciles).mean().sort_index(ascending=False)['Total_Spend']\n",
    "\n",
    "Decile_analysis_test = pd.concat([Predicted_avg, Actual_avg], axis=1)\n",
    "\n",
    "Decile_analysis_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decile_analysis_test.to_excel(\"Decile_Test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y =np.exp(Final_data.Total_Spend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Pre_Final_Data.loc[:,[\"card2_2\",\"card2_3\",\"card2_4\",\"card2_5\",\"card_2\",\"card_3\",\"card_4\",\"card_5\",\"carown_0\",\"carown_1\",\"carvalue\",\"creddebt\",\"ed\",\"gender_1\",\"income\",\"internet\",\"othdebt\",\"owncd_1\",\"owndvd_1\",\"ownvcr_1\",\"reason_2\",\"reason_4\",\"retire_1\",\"wireten\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,Y,test_size = 0.3,random_state= 345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Data = sc.fit_transform(X)\n",
    "KNN_Data = pd.DataFrame(KNN_Data)\n",
    "KNN_Data.columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1, test_x1, train_y1, test_y1 = train_test_split(KNN_Data,Y,test_size=0.3, random_state = 888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = [{\"n_neighbors\" : [3,5,7,9,11,13], \"leaf_size\" : [20,30,40,50,60]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = GridSearchCV(KNeighborsRegressor(),param_grid_knn,cv=3,scoring=\"r2\")\n",
    "knn_model= model_knn.fit(train_X1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_model.best_params_)\n",
    "print(knn_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_knn = KNeighborsRegressor(n_neighbors=13,leaf_size=20)\n",
    "best_model_knn.fit(train_X1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2 = metrics.r2_score(train_y1,best_model_knn.predict(train_X1))\n",
    "print(\"R-Square Train:\",train_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_knn.fit(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error KNN Train:\",metrics.mean_absolute_error(train_y1,best_model_knn.predict(train_X1)))\n",
    "print(\"Mean Absolute Error KNN Test:\",metrics.mean_absolute_error(test_y1,best_model_knn.predict(test_x1)))\n",
    "print(\"Mean Square Error KNN Train:\",metrics.mean_squared_error(train_y1,best_model_knn.predict(train_X1)))\n",
    "print(\"Mean Square Error KNN Test:\",metrics.mean_squared_error(test_y1,best_model_knn.predict(test_x1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_knn = train_y1-best_model_knn.predict(train_X1)\n",
    "abs_error_knn = abs(error_knn)\n",
    "abs_pct_error_knn = abs_error_knn/train_y1\n",
    "MAPE_knn = abs_pct_error_knn.mean()\n",
    "print(\"MAPE KNN Train:\",MAPE_knn)\n",
    "\n",
    "error_knn_test = test_y1-best_model_knn.predict(test_x1)\n",
    "abs_error_knn_test = abs(error_knn_test)\n",
    "abs_pct_error_knn_test = abs_error_knn_test/test_y1\n",
    "MAPE_knn_test = abs_pct_error_knn_test.mean()\n",
    "print(\"MAPE KNN Test:\",MAPE_knn_test)\n",
    "\n",
    "print(\"RMSE KNN Train:\",metrics.mean_squared_error(train_y1,best_model_knn.predict(train_X1))**(1/2))\n",
    "print(\"RMSE KNN Test:\",metrics.mean_squared_error(test_y1,best_model_knn.predict(test_x1))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = {\"R_Square_knn\":train_r2,\"Mape_Train_knn\":MAPE_knn,\"Mape_Test_knn\":MAPE_knn_test,\n",
    "       \"RMSE_Train_knn\":[metrics.mean_squared_error(train_y1,best_model_knn.predict(train_X1))**(1/2)],\n",
    "      \"RMSE_Test_knn\":[metrics.mean_squared_error(test_y1,best_model_knn.predict(test_x1))**(1/2)]}\n",
    "knn = pd.DataFrame.from_dict(knn)\n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dtr = {\"max_depth\":np.arange(2,5),\"max_features\": np.arange(4,7),\"random_state\":[100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtr = GridSearchCV(DecisionTreeRegressor(),param_grid_dtr,cv = 3,scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtr.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_dtr.best_params_)\n",
    "print(model_dtr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_dtr = DecisionTreeRegressor(max_depth=4,max_features=6)\n",
    "best_model_dtr.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_DT_TRAIN = metrics.r2_score(train_y,best_model_dtr.predict(train_X))\n",
    "R2_DT_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_dtr.fit(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error Train:\",metrics.mean_absolute_error(train_y,best_model_dtr.predict(train_X)))\n",
    "print(\"Mean Absolute Error Test:\",metrics.mean_absolute_error(test_y,best_model_dtr.predict(test_X)))\n",
    "\n",
    "print(\"Mean Square Error DT Train:\",metrics.mean_squared_error(train_y,best_model_dtr.predict(train_X)))\n",
    "print(\"Mean Square Error DT Test:\",metrics.mean_squared_error(test_y,best_model_dtr.predict(test_X)))\n",
    "\n",
    "error_dt = train_y-best_model_dtr.predict(train_X)\n",
    "abs_error_dt = abs(error_dt)\n",
    "abs_pct_error_dt = abs_error_dt/train_y\n",
    "MAPE_dt = abs_pct_error_dt.mean()\n",
    "print(\"MAPE Decision Tree Train:\",MAPE_dt)\n",
    "\n",
    "error_dt_test = test_y-best_model_dtr.predict(test_X)\n",
    "abs_error_dt_test = abs(error_dt_test)\n",
    "abs_pct_error_dt_test = abs_error_dt_test/test_y\n",
    "MAPE_dt_test = abs_pct_error_dt_test.mean()\n",
    "print(\"MAPE Decision Tree Test:\",MAPE_dt_test)\n",
    "\n",
    "print(\"RMSE Decision Tree Train:\",metrics.mean_squared_error(train_y,best_model_dtr.predict(train_X))**(1/2))\n",
    "print(\"RMSE Decision Tree Test:\",metrics.mean_squared_error(test_y,best_model_dtr.predict(test_X))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = {\"R_Square_dt\":R2_DT_TRAIN,\n",
    "      \"Mape_Train_dt\":MAPE_dt,\n",
    "      \"Mape_Test_dt\":MAPE_dt_test,\n",
    "       \"RMSE_Train_dt\":[metrics.mean_squared_error(train_y,best_model_dtr.predict(train_X))**(1/2)],\n",
    "      \"RMSE_Test_dt\":[metrics.mean_squared_error(test_y,best_model_dtr.predict(test_X))**(1/2)]}\n",
    "DT = pd.DataFrame.from_dict(DT)\n",
    "DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_dtr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = pd.DataFrame([train_X.columns, best_model_dtr.feature_importances_]).T\n",
    "var_imp.columns = ['var', 'imp']\n",
    "var_imp.sort_values(by= 'imp', inplace=True)\n",
    "var_imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learnig - Bagging,RandomForset,AdaBoost and GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_bagg = {\"n_estimators\":[50,60,70,80,90,100],\"random_state\":[67]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bagg = GridSearchCV(BaggingRegressor(),param_grid=param_grid_bagg,cv=3,n_jobs=-1)\n",
    "model_bagg.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bagg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_bagg = BaggingRegressor(n_estimators=100)\n",
    "best_model_bagg.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Sqaure_Bagging= metrics.r2_score(train_y,best_model_bagg.predict(train_X))\n",
    "R_Sqaure_Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_bagg.fit(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error Train:\",metrics.mean_absolute_error(train_y,best_model_bagg.predict(train_X)))\n",
    "print(\"Mean Absolute Error Test:\",metrics.mean_absolute_error(test_y,best_model_bagg.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Square Error Bagging Train:\",metrics.mean_squared_error(train_y,best_model_bagg.predict(train_X)))\n",
    "print(\"Mean Square Error Bagging Test:\",metrics.mean_squared_error(test_y,best_model_bagg.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_Bagg = train_y-best_model_bagg.predict(train_X)\n",
    "abs_error_Bagg = abs(error_Bagg)\n",
    "abs_pct_error_bagg = abs_error_Bagg/train_y\n",
    "MAPE_bagg = abs_pct_error_bagg.mean()\n",
    "print(\"MAPE Bagging Train:\",MAPE_bagg)\n",
    "\n",
    "error_bagg_test = test_y-best_model_bagg.predict(test_X)\n",
    "abs_error_bagg_test = abs(error_bagg_test)\n",
    "abs_pct_error_bagg_test = abs_error_bagg_test/test_y\n",
    "MAPE_bagg_test = abs_pct_error_bagg_test.mean()\n",
    "print(\"MAPE Bagging Test:\",MAPE_bagg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE Bagging Train:\",metrics.mean_squared_error(train_y,best_model_bagg.predict(train_X))**(1/2))\n",
    "print(\"RMSE Bagging Test:\",metrics.mean_squared_error(test_y,best_model_bagg.predict(test_X))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging = {\"R_Square_bagging\":R_Sqaure_Bagging,\n",
    "      \"Mape_Train_bagging\":MAPE_bagg,\n",
    "      \"Mape_Test_bagging\":MAPE_bagg_test,\n",
    "       \"RMSE_Train_bagging\":[metrics.mean_squared_error(train_y,best_model_bagg.predict(train_X))**(1/2)],\n",
    "      \"RMSE_Test_bagging\":[metrics.mean_squared_error(test_y,best_model_bagg.predict(test_X))**(1/2)]}\n",
    "Bagging = pd.DataFrame.from_dict(Bagging)\n",
    "Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\"n_estimators\":[50,60,70,80,90,100],\"max_depth\":[2,3,4],\"random_state\":[89]}\n",
    "model_rf = GridSearchCV(RandomForestRegressor(),param_grid=param_grid_rf,cv = 3, n_jobs=-1)\n",
    "model_rf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_rf.best_params_)\n",
    "print(model_rf.best_score_)\n",
    "print(model_rf.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rf = RandomForestRegressor(n_estimators=50,max_depth=4)\n",
    "result_rf = best_model_rf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_RF_Train= metrics.r2_score(train_y,result_rf.predict(train_X))\n",
    "R2_RF_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf_test = best_model_rf.fit(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error Train:\",metrics.mean_absolute_error(train_y,result_rf.predict(train_X)))\n",
    "print(\"Mean Absolute Error Test:\",metrics.mean_absolute_error(test_y,result_rf_test.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Square Error RF Train:\",metrics.mean_squared_error(train_y,result_rf.predict(train_X)))\n",
    "print(\"Mean Square Error RF Test:\",metrics.mean_squared_error(test_y,result_rf_test.predict(test_X)))\n",
    "print(\"RMSE RF Train:\",metrics.mean_squared_error(train_y,result_rf.predict(train_X))**(1/2))\n",
    "print(\"RMSE RF Test:\",metrics.mean_squared_error(test_y,result_rf_test.predict(test_X))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rf_train = train_y-result_rf.predict(train_X)\n",
    "abs_error_rf_train = abs(error_rf_train)\n",
    "abs_pct_error_rf_train = abs_error_rf_train/train_y\n",
    "MAPE_rf_train = abs_pct_error_rf_train.mean()\n",
    "print(\"MAPE RF Train:\",MAPE_rf_train)\n",
    "\n",
    "\n",
    "error_rf_test = test_y-result_rf_test.predict(test_X)\n",
    "abs_error_rf_test = abs(error_rf_test)\n",
    "abs_pct_error_rf_test = abs_error_rf_test/test_y\n",
    "MAPE_rf_test = abs_pct_error_rf_test.mean()\n",
    "print(\"MAPE RF Test:\",MAPE_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Forest = {\"R_Square_rf\":R2_RF_Train,\n",
    "      \"Mape_Train_rf\":MAPE_rf_train,\n",
    "      \"Mape_Test_rf\":MAPE_rf_test,\n",
    "       \"RMSE_Train_rf\":[metrics.mean_squared_error(train_y,result_rf.predict(train_X))**(1/2)],\n",
    "      \"RMSE_Test_rf\":[metrics.mean_squared_error(test_y,result_rf_test.predict(test_X))**(1/2)]}\n",
    "Random_Forest = pd.DataFrame.from_dict(Random_Forest)\n",
    "Random_Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.stats.pearsonr(train_y,error_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.stats.pearsonr(train_y,result_rf.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.stats.pearsonr(test_y,error_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.stats.pearsonr(test_y,result_rf_test.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf.feature_importances_\n",
    "indices = np.argsort(result_rf.feature_importances_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(result_rf.feature_importances_)[::-1]\n",
    "feature_rank = pd.DataFrame( columns = ['rank', 'feature', 'importance'] )\n",
    "for f in range(train_X.shape[1]):\n",
    "  feature_rank.loc[f] = [f+1,\n",
    "                         train_X.columns[indices[f]],\n",
    "                         result_rf.feature_importances_[indices[f]]]\n",
    "sns.barplot( y = 'feature', x = 'importance', data = feature_rank )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ada = {\"n_estimators\":[60,70,80,90,100],\"learning_rate\":[10**x for x in range(-4,2)]}\n",
    "model_ada = GridSearchCV(AdaBoostRegressor(),param_grid=param_grid_ada,cv=3,verbose=True,n_jobs=-1)\n",
    "result_ada = model_ada.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_ada.best_params_)\n",
    "print(result_ada.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_ada = AdaBoostRegressor(n_estimators=60,learning_rate=0.1)\n",
    "result_ada = best_model_ada.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ada.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_Ada_Train = metrics.r2_score(train_y,result_ada.predict(train_X))\n",
    "R2_Ada_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ada_test = best_model_ada.fit(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error Train:\",metrics.mean_absolute_error(train_y,result_ada.predict(train_X)))\n",
    "print(\"Mean Absolute Error Test:\",metrics.mean_absolute_error(test_y,result_ada_test.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Square Error RF Train:\",metrics.mean_squared_error(train_y,result_ada.predict(train_X)))\n",
    "print(\"Mean Square Error RF Test:\",metrics.mean_squared_error(test_y,result_ada_test.predict(test_X)))\n",
    "print(\"RMSE RF Train:\",metrics.mean_squared_error(train_y,result_ada.predict(train_X))**(1/2))\n",
    "print(\"RMSE RF Test:\",metrics.mean_squared_error(test_y,result_ada_test.predict(test_X))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_ada_train = train_y-result_ada.predict(train_X)\n",
    "abs_error_ada_train = abs(error_ada_train)\n",
    "abs_pct_error_ada_train = abs_error_ada_train/train_y\n",
    "MAPE_ada_train = abs_pct_error_ada_train.mean()\n",
    "print(\"MAPE ADA Train:\",MAPE_ada_train)\n",
    "\n",
    "\n",
    "error_ada_test = test_y-result_ada_test.predict(test_X)\n",
    "abs_error_ada_test = abs(error_ada_test)\n",
    "abs_pct_error_ada_test = abs_error_ada_test/test_y\n",
    "MAPE_ada_test = abs_pct_error_ada_test.mean()\n",
    "print(\"MAPE ADA Test:\",MAPE_ada_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_Boost = {\"R_Square_ada\":R2_Ada_Train,\n",
    "      \"Mape_Train_ada\":MAPE_ada_train,\n",
    "      \"Mape_Test_ada\":MAPE_ada_test,\n",
    "       \"RMSE_Train_ada\":[metrics.mean_squared_error(train_y,result_ada.predict(train_X))**(1/2)],\n",
    "      \"RMSE_Test_ada\":[metrics.mean_squared_error(test_y,result_ada_test.predict(test_X))**(1/2)]}\n",
    "Ada_Boost = pd.DataFrame.from_dict(Ada_Boost)\n",
    "Ada_Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_gbm = {\"n_estimators\":[60,70,80,90,100],\n",
    "                 \"max_depth\":[2,3,4,5],\n",
    "                 \"learning_rate\":[10**x for x in range(-4,2)],\n",
    "                 \"random_state\":[56]}\n",
    "model_gbm = GridSearchCV(GradientBoostingRegressor(),param_grid=param_grid_gbm,cv = 3, verbose=True,n_jobs=-1)\n",
    "result_gbm = model_gbm.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\",result_gbm.best_params_)\n",
    "print(\"Best Scores:\",result_gbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_gbm = GradientBoostingRegressor(n_estimators=100,max_depth=3,learning_rate=0.1)\n",
    "result_gbm = best_model_gbm.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_GBM_Train = metrics.r2_score(train_y,result_gbm.predict(train_X))\n",
    "R2_GBM_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gbm_test = best_model_gbm.fit(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE GBM TRAIN:\",metrics.mean_absolute_error(train_y,result_gbm.predict(train_X)))\n",
    "print(\"MAE GBM TEST:\",metrics.mean_absolute_error(test_y,result_gbm_test.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE GBM TRAIN:\",metrics.mean_squared_error(train_y,result_gbm.predict(train_X)))\n",
    "print(\"MSE GBM TEST:\",metrics.mean_squared_error(test_y,result_gbm_test.predict(test_X)))\n",
    "print(\"RMSE GBM TRAIN:\",metrics.mean_squared_error(train_y,result_gbm.predict(train_X))**(1/2))\n",
    "print(\"RMSE GBM TEST:\",metrics.mean_squared_error(test_y,result_gbm_test.predict(test_X))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_gbm_train = train_y - result_gbm.predict(train_X)\n",
    "abs_error_gbm_train = abs(error_gbm_train)\n",
    "abs_pct_error_gbm_train  = abs_error_gbm_train/train_y\n",
    "mape_gbm_train = abs_pct_error_gbm_train.mean()\n",
    "print(\"MAPE GBM TRAIN:\",mape_gbm_train)\n",
    "\n",
    "\n",
    "error_gbm_test = test_y - result_gbm_test.predict(test_X)\n",
    "abs_error_gbm_test = abs(error_gbm_test)\n",
    "abs_pct_error_gbm_test  = abs_error_gbm_test/test_y\n",
    "mape_gbm_test = abs_pct_error_gbm_test.mean()\n",
    "print(\"MAPE GBM TREST:\",mape_gbm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM = {\"R_Square_GBM\":R2_GBM_Train,\n",
    "      \"Mape_Train_GBM\":mape_gbm_train,\n",
    "      \"Mape_Test_GBM\":mape_gbm_test,\n",
    "       \"RMSE_Train_GBM\":[metrics.mean_squared_error(train_y,result_gbm.predict(train_X))**(1/2)],\n",
    "      \"RMSE_Test_GBM\":[metrics.mean_squared_error(test_y,result_gbm_test.predict(test_X))**(1/2)]}\n",
    "GBM = pd.DataFrame.from_dict(GBM)\n",
    "GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xg = {\"n_estimators\":[60,70,80,90,100,120],\n",
    "                \"max_depth\":[2,3,4,5]}\n",
    "model_xg = GridSearchCV(xgboost.XGBRegressor(),param_grid=param_grid_xg,cv=3,n_jobs=-1)\n",
    "result_xg = model_xg.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parmaeters:\",result_xg.best_params_)\n",
    "print(\"Best Score:\",result_xg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_xg = xgboost.XGBRegressor(n_estimators = 70,max_depth=2)\n",
    "result_xg = best_model_xg.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_XG_Train=metrics.r2_score(train_y,result_xg.predict(train_X))\n",
    "R2_XG_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xg_test = best_model_xg.fit(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE XG TRAIN:\",metrics.mean_squared_error(train_y,result_xg.predict(train_X))**(1/2))\n",
    "print(\"RMSE XG TEST:\",metrics.mean_squared_error(test_y,result_xg_test.predict(test_X))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_xg_train = train_y - result_xg.predict(train_X)\n",
    "abs_error_xg_train = abs(error_xg_train)\n",
    "abs_pct_error_xg_train  = abs_error_xg_train/train_y\n",
    "mape_xg_train = abs_pct_error_xg_train.mean()\n",
    "print(\"MAPE XG TRAIN:\",mape_xg_train)\n",
    "\n",
    "\n",
    "error_xg_test = test_y - result_xg_test.predict(test_X)\n",
    "abs_error_xg_test = abs(error_xg_test)\n",
    "abs_pct_error_xg_test  = abs_error_xg_test/test_y\n",
    "mape_xg_test = abs_pct_error_xg_test.mean()\n",
    "print(\"MAPE XG TEST:\",mape_xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGboost = {\"R_Square_xg\":R2_XG_Train,\n",
    "      \"Mape_Train_xg\":mape_xg_train,\n",
    "      \"Mape_Test_xg\":mape_xg_test,\n",
    "       \"RMSE_Train_xg\":[metrics.mean_squared_error(train_y,result_xg.predict(train_X))**(1/2)],\n",
    "      \"RMSE_Test_xg\":[metrics.mean_squared_error(test_y,result_xg_test.predict(test_X))**(1/2)]}\n",
    "XGboost = pd.DataFrame.from_dict(XGboost)\n",
    "XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xg.feature_importances_\n",
    "indices = np.argsort(result_xg.feature_importances_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(result_xg.feature_importances_)[::-1]\n",
    "feature_rank_xg = pd.DataFrame( columns = ['rank', 'feature', 'importance'] )\n",
    "for f in range(train_X.shape[1]):\n",
    "  feature_rank_xg.loc[f] = [f+1,\n",
    "                         train_X.columns[indices[f]],\n",
    "                         result_xg.feature_importances_[indices[f]]]\n",
    "sns.barplot( y = 'feature', x = 'importance', data = feature_rank )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ols)\n",
    "print(knn)\n",
    "print(DT)\n",
    "print(Bagging)\n",
    "print(Random_Forest)\n",
    "print(Ada_Boost)\n",
    "print(GBM)\n",
    "print(XGboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
